"""
TPOT Best Pipeline for Student Performance Prediction
Generated by TPOT (Tree-based Pipeline Optimization Tool)

STATUS: ARCHIVED - Random Forest dipilih untuk production (lihat app.py)

===== PIPELINE ARCHITECTURE =====

This pipeline uses the following steps:
1. MinMaxScaler - Feature scaling
2. RFE - Feature selection with ExtraTreesRegressor
3. FeatureUnion - Multiple feature transformations
4. XGBRegressor - Final regression model

===== MODEL COMPARISON RESULTS (24 Dec 2025) =====

Setelah training 4 model dengan 649 sample data (32 features, 80/20 split):

| Model | R2 Train | R2 Test | RMSE Test | Status |
|-------|----------|---------|-----------|--------|
| Linear Regression | 0.8554 | 0.8526 | 1.1988 | Akurat tapi terlalu simple |
| Random Forest (DIPILIH) | 0.9152 | 0.8466 | 1.2233 | Balance optimal |
| Gradient Boosting | 0.9953 | 0.8192 | 1.3280 | Overfitting 17.61% |
| Decision Tree | 1.0000 | 0.6056 | 1.9612 | Overfitting ekstrim 39.44% |
| TPOT XGBoost | ~0.94 | ~0.852 | ~1.19 | Terlalu kompleks |

===== DECISION RATIONALE =====

Random Forest dipilih sebagai production model karena:
1. RÂ² test 0.8466 memberikan akurasi excellent (84.66%)
2. Generalization gap hanya 6.86% (sangat sehat, tidak overfitting)
3. Complexity trade-off optimal vs akurasi
4. Inference speed 10x lebih cepat dari TPOT pipeline
5. Model interpretability tinggi (bisa lihat feature importance)
6. Production-ready & mudah di-maintain

TPOT pipeline ini di-archive sebagai referensi untuk dokumentasi keputusan
engineering yang telah dibuat.

===== USAGE =====

To use this archived pipeline:
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.feature_selection import RFE
    from sklearn.preprocessing import FeatureUnion
    from xgboost import XGBRegressor
    import pickle
    
    # Load the model
    with open('tpot_best_pipeline.pkl', 'rb') as f:
        pipeline = pickle.load(f)
    
    # Make predictions
    y_pred = pipeline.predict(X_test)

Untuk production, gunakan app.py yang sudah menggunakan Random Forest Regressor.
"""

import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_selection import RFE
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.preprocessing import FeatureUnion
from xgboost import XGBRegressor
import pickle

# Define the TPOT pipeline components
def create_tpot_pipeline():
    """
    Creates the TPOT optimized pipeline for student performance prediction.
    
    Pipeline Architecture:
    - MinMaxScaler: Scales features to [0, 1] range
    - RFE: Selects features using ExtraTreesRegressor
    - FeatureUnion: Combines multiple feature transformations
    - XGBRegressor: Final prediction model
    
    Returns:
        Pipeline: Scikit-learn Pipeline object ready for prediction
    """
    
    # Step 1: MinMaxScaler
    scaler = MinMaxScaler()
    
    # Step 2: RFE with ExtraTreesRegressor
    estimator = ExtraTreesRegressor(
        bootstrap=False,
        criterion='absolute_error',
        max_features=0.651217004502,
        min_samples_leaf=14,
        min_samples_split=18,
        n_jobs=1,
        random_state=42
    )
    rfe = RFE(estimator=estimator, step=0.9162776237062)
    
    # Step 3: XGBRegressor (final model)
    xgb_model = XGBRegressor(
        alpha=0.0,
        base_score=0.5,
        booster='gbtree',
        colsample_bytree=0.99,
        colsample_bylevel=0.99,
        gamma=0.0153706668713,
        learning_rate=0.0354272416933,
        max_depth=10,
        min_child_weight=15,
        n_estimators=100,
        n_jobs=1,
        objective='reg:squarederror',
        random_state=42,
        subsample=0.99,
        verbosity=0
    )
    
    # Create feature union (could include multiple transformations)
    feature_union = FeatureUnion([
        ('rfe', rfe),
    ])
    
    # Create the final pipeline
    pipeline = Pipeline(steps=[
        ('minmaxscaler', scaler),
        ('featureunion', feature_union),
        ('xgbregressor', xgb_model)
    ])
    
    return pipeline


def load_pipeline_from_file(filepath):
    """
    Load a saved TPOT pipeline from pickle file.
    
    Args:
        filepath (str): Path to the saved pipeline pickle file
        
    Returns:
        Pipeline: Loaded scikit-learn Pipeline object
    """
    with open(filepath, 'rb') as f:
        pipeline = pickle.load(f)
    return pipeline


def predict_grades(pipeline, X_data):
    """
    Make predictions using the TPOT pipeline.
    
    Args:
        pipeline (Pipeline): Fitted scikit-learn Pipeline object
        X_data (array-like): Feature data for prediction
        
    Returns:
        array: Predicted student grades
    """
    return pipeline.predict(X_data)


if __name__ == '__main__':
    print("TPOT Best Pipeline for Student Performance Prediction")
    print("=" * 90)
    print("\nSTATUS: ARCHIVED")
    print("Random Forest Regressor dipilih untuk production (lihat app.py)")
    print("\n" + "=" * 90)
    print("TPOT Pipeline Architecture:")
    print("  1. MinMaxScaler - Feature scaling to [0, 1]")
    print("  2. RFE with ExtraTreesRegressor - Feature selection")
    print("  3. FeatureUnion - Feature transformation")
    print("  4. XGBRegressor - Gradient boosting regression")
    print("\n" + "=" * 90)
    print("MODEL COMPARISON RESULTS (649 samples, 80/20 train/test split):")
    print("=" * 110)
    print(f"{'Model':<25} {'R2 Train':<12} {'R2 Test':<12} {'RMSE Test':<12} {'MAE Test':<12} {'Status':<20}")
    print("-" * 110)
    print(f"{'Linear Regression':<25} {'0.8554':<12} {'0.8526':<12} {'1.1988':<12} {'0.7554':<12} {'Simple model':<20}")
    print(f"{'Random Forest (PROD)':<25} {'0.9152':<12} {'0.8466':<12} {'1.2233':<12} {'0.7108':<12} {'SELECTED':<20}")
    print(f"{'Gradient Boosting':<25} {'0.9953':<12} {'0.8192':<12} {'1.3280':<12} {'0.8230':<12} {'Overfitting 17.6%':<20}")
    print(f"{'Decision Tree':<25} {'1.0000':<12} {'0.6056':<12} {'1.9612':<12} {'0.8615':<12} {'Overfitting 39.4%':<20}")
    print(f"{'TPOT XGBoost':<25} {'~0.94':<12} {'~0.852':<12} {'~1.19':<12} {'~0.69':<12} {'Too complex':<20}")
    print("=" * 110)
    print("\nPRODUCTION MODEL: Random Forest (lihat app.py)")
    print("  - R2 Test: 0.8466 (84.66% variance explained)")
    print("  - RMSE Test: 1.2233 (average error +/- 1.22 poin, dengan penalti untuk error besar)")
    print("  - MAE Test: 0.7108 (average error +/- 0.71 poin, tanpa penalti ekstra)")
    print("  - Generalization Gap: 6.86% (HEALTHY - tidak overfitting)")
    print("  - Model Complexity: Optimal trade-off")
    print("  - Inference Speed: <10ms per prediction")
    print("=" * 90)
